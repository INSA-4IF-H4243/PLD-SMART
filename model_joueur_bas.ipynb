{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle de réseau de neurones sur le dataset du Joueur bas - Henri, Minh, Maxime\n",
    "- Coup droit\n",
    "- Déplacement\n",
    "- Revers\n",
    "- Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from smart.video import Video, Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "path_dataset = 'img/JBas'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau de neurones classique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prises des frames et des vidéos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_videos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "all_paths = []\n",
    "for dirpath, dirnames, _ in os.walk(path_dataset):\n",
    "    for dir_type in dirnames:\n",
    "        \n",
    "        path_fol = os.path.join(dirpath, dir_type)\n",
    "        for file in os.listdir(path_fol):\n",
    "            path_fol_img = os.path.join(path_fol, file)\n",
    "            if os.path.isdir(path_fol_img) and file == 'images':\n",
    "                frames = []\n",
    "                for file_img in os.listdir(path_fol_img):\n",
    "                    path_img = os.path.join(path_fol_img, file_img)\n",
    "                    img_obj = Image.load_image(cv2.IMREAD_GRAYSCALE, path_img)\n",
    "                    img = img_obj.img\n",
    "                    frames.append(img)\t\n",
    "                if (len(frames) == 15):\n",
    "                    output_res = path_img.split('\\\\')[1]\n",
    "                    all_paths.append(path_fol_img)\n",
    "                    vid = Video.read_video_from_frames(frames)\n",
    "                    list_videos.append(vid)\n",
    "                    y.append(output_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<smart.video.Video.Video at 0x11627ea8100>,\n",
       " <smart.video.Video.Video at 0x11626032220>,\n",
       " <smart.video.Video.Video at 0x116260322e0>,\n",
       " <smart.video.Video.Video at 0x11626032340>,\n",
       " <smart.video.Video.Video at 0x116260323a0>,\n",
       " <smart.video.Video.Video at 0x11626032430>,\n",
       " <smart.video.Video.Video at 0x116260324c0>,\n",
       " <smart.video.Video.Video at 0x116260324f0>,\n",
       " <smart.video.Video.Video at 0x11626032580>,\n",
       " <smart.video.Video.Video at 0x11626032490>,\n",
       " <smart.video.Video.Video at 0x116260325e0>,\n",
       " <smart.video.Video.Video at 0x116260320d0>,\n",
       " <smart.video.Video.Video at 0x11626032070>,\n",
       " <smart.video.Video.Video at 0x11626032610>,\n",
       " <smart.video.Video.Video at 0x11626032670>,\n",
       " <smart.video.Video.Video at 0x11626032760>,\n",
       " <smart.video.Video.Video at 0x11626032700>,\n",
       " <smart.video.Video.Video at 0x116260326a0>,\n",
       " <smart.video.Video.Video at 0x11626032160>,\n",
       " <smart.video.Video.Video at 0x11625fbcf10>,\n",
       " <smart.video.Video.Video at 0x11627ecb580>,\n",
       " <smart.video.Video.Video at 0x11627ecbdc0>,\n",
       " <smart.video.Video.Video at 0x11626032520>,\n",
       " <smart.video.Video.Video at 0x11626032190>,\n",
       " <smart.video.Video.Video at 0x11625fc05b0>,\n",
       " <smart.video.Video.Video at 0x11625fc06d0>,\n",
       " <smart.video.Video.Video at 0x11625fc0910>,\n",
       " <smart.video.Video.Video at 0x11625fcc730>,\n",
       " <smart.video.Video.Video at 0x11625fcc4f0>,\n",
       " <smart.video.Video.Video at 0x11625fcc1c0>,\n",
       " <smart.video.Video.Video at 0x11625fcc8b0>,\n",
       " <smart.video.Video.Video at 0x1162848e820>,\n",
       " <smart.video.Video.Video at 0x11625fccc70>,\n",
       " <smart.video.Video.Video at 0x11625ff8640>,\n",
       " <smart.video.Video.Video at 0x11625ff8580>,\n",
       " <smart.video.Video.Video at 0x11625ff8820>,\n",
       " <smart.video.Video.Video at 0x11625ff88e0>,\n",
       " <smart.video.Video.Video at 0x11625ff8610>,\n",
       " <smart.video.Video.Video at 0x11625ff8670>,\n",
       " <smart.video.Video.Video at 0x11625ff8790>,\n",
       " <smart.video.Video.Video at 0x11625ff88b0>,\n",
       " <smart.video.Video.Video at 0x11625ff86a0>,\n",
       " <smart.video.Video.Video at 0x11625ff8520>,\n",
       " <smart.video.Video.Video at 0x11625fcc970>,\n",
       " <smart.video.Video.Video at 0x11626017310>,\n",
       " <smart.video.Video.Video at 0x11626017700>,\n",
       " <smart.video.Video.Video at 0x11626017bb0>,\n",
       " <smart.video.Video.Video at 0x11626017b20>,\n",
       " <smart.video.Video.Video at 0x11625ff8b20>,\n",
       " <smart.video.Video.Video at 0x11626017eb0>,\n",
       " <smart.video.Video.Video at 0x116260277c0>,\n",
       " <smart.video.Video.Video at 0x11626027670>,\n",
       " <smart.video.Video.Video at 0x11626027880>,\n",
       " <smart.video.Video.Video at 0x116260276d0>,\n",
       " <smart.video.Video.Video at 0x116260278b0>,\n",
       " <smart.video.Video.Video at 0x11626027910>,\n",
       " <smart.video.Video.Video at 0x11626027220>,\n",
       " <smart.video.Video.Video at 0x116260270d0>,\n",
       " <smart.video.Video.Video at 0x116260271f0>,\n",
       " <smart.video.Video.Video at 0x116260272e0>,\n",
       " <smart.video.Video.Video at 0x11626027820>,\n",
       " <smart.video.Video.Video at 0x11626027730>,\n",
       " <smart.video.Video.Video at 0x11626027490>,\n",
       " <smart.video.Video.Video at 0x11626027460>,\n",
       " <smart.video.Video.Video at 0x11626027340>,\n",
       " <smart.video.Video.Video at 0x116260273a0>,\n",
       " <smart.video.Video.Video at 0x11626027c70>,\n",
       " <smart.video.Video.Video at 0x11626027be0>,\n",
       " <smart.video.Video.Video at 0x11626027c10>,\n",
       " <smart.video.Video.Video at 0x11626027b20>,\n",
       " <smart.video.Video.Video at 0x11626027b50>,\n",
       " <smart.video.Video.Video at 0x11626027d30>,\n",
       " <smart.video.Video.Video at 0x11626027d90>,\n",
       " <smart.video.Video.Video at 0x11626027e20>,\n",
       " <smart.video.Video.Video at 0x11626027df0>,\n",
       " <smart.video.Video.Video at 0x11626027eb0>,\n",
       " <smart.video.Video.Video at 0x11626027f10>,\n",
       " <smart.video.Video.Video at 0x11626027f70>,\n",
       " <smart.video.Video.Video at 0x11626027610>,\n",
       " <smart.video.Video.Video at 0x11626027430>,\n",
       " <smart.video.Video.Video at 0x11626027550>,\n",
       " <smart.video.Video.Video at 0x116260275b0>,\n",
       " <smart.video.Video.Video at 0x116260279d0>,\n",
       " <smart.video.Video.Video at 0x11626027a30>,\n",
       " <smart.video.Video.Video at 0x11626027cd0>,\n",
       " <smart.video.Video.Video at 0x11626017760>,\n",
       " <smart.video.Video.Video at 0x11625fd3850>,\n",
       " <smart.video.Video.Video at 0x116260276a0>,\n",
       " <smart.video.Video.Video at 0x11625fd3640>,\n",
       " <smart.video.Video.Video at 0x11625ffd3a0>,\n",
       " <smart.video.Video.Video at 0x11625fd8640>,\n",
       " <smart.video.Video.Video at 0x11626027970>,\n",
       " <smart.video.Video.Video at 0x11625ff1340>,\n",
       " <smart.video.Video.Video at 0x1162526bd90>,\n",
       " <smart.video.Video.Video at 0x1162843cf70>,\n",
       " <smart.video.Video.Video at 0x1162526bbb0>,\n",
       " <smart.video.Video.Video at 0x1162603b0d0>,\n",
       " <smart.video.Video.Video at 0x1162603b070>,\n",
       " <smart.video.Video.Video at 0x1162603b160>,\n",
       " <smart.video.Video.Video at 0x1162603b1c0>,\n",
       " <smart.video.Video.Video at 0x1162603b220>,\n",
       " <smart.video.Video.Video at 0x1162603b280>,\n",
       " <smart.video.Video.Video at 0x1162603b2e0>,\n",
       " <smart.video.Video.Video at 0x1162603b340>,\n",
       " <smart.video.Video.Video at 0x1162603b3a0>,\n",
       " <smart.video.Video.Video at 0x1162603b400>,\n",
       " <smart.video.Video.Video at 0x1162603b460>,\n",
       " <smart.video.Video.Video at 0x1162603b4c0>,\n",
       " <smart.video.Video.Video at 0x1162603b520>,\n",
       " <smart.video.Video.Video at 0x1162603b580>,\n",
       " <smart.video.Video.Video at 0x1162603b5e0>,\n",
       " <smart.video.Video.Video at 0x1162603b640>,\n",
       " <smart.video.Video.Video at 0x1162603b6a0>,\n",
       " <smart.video.Video.Video at 0x1162603b700>,\n",
       " <smart.video.Video.Video at 0x1162603b760>,\n",
       " <smart.video.Video.Video at 0x1162603b7c0>,\n",
       " <smart.video.Video.Video at 0x1162603b820>,\n",
       " <smart.video.Video.Video at 0x1162603b880>,\n",
       " <smart.video.Video.Video at 0x1162603b8e0>,\n",
       " <smart.video.Video.Video at 0x1162603b940>,\n",
       " <smart.video.Video.Video at 0x1162603b9a0>,\n",
       " <smart.video.Video.Video at 0x1162603ba00>,\n",
       " <smart.video.Video.Video at 0x1162603ba60>,\n",
       " <smart.video.Video.Video at 0x1162603bac0>,\n",
       " <smart.video.Video.Video at 0x1162603bb20>,\n",
       " <smart.video.Video.Video at 0x1162603bb80>,\n",
       " <smart.video.Video.Video at 0x1162603bbe0>,\n",
       " <smart.video.Video.Video at 0x1162603bc40>,\n",
       " <smart.video.Video.Video at 0x1162603bca0>,\n",
       " <smart.video.Video.Video at 0x1162603bd00>,\n",
       " <smart.video.Video.Video at 0x1162603bd60>,\n",
       " <smart.video.Video.Video at 0x1162603bdc0>,\n",
       " <smart.video.Video.Video at 0x1162603be20>,\n",
       " <smart.video.Video.Video at 0x1162603be80>,\n",
       " <smart.video.Video.Video at 0x1162603bee0>,\n",
       " <smart.video.Video.Video at 0x1162603bf40>,\n",
       " <smart.video.Video.Video at 0x1162603bf70>,\n",
       " <smart.video.Video.Video at 0x11625fdfa90>,\n",
       " <smart.video.Video.Video at 0x1162603b0a0>,\n",
       " <smart.video.Video.Video at 0x1162603f0d0>,\n",
       " <smart.video.Video.Video at 0x1162603f130>,\n",
       " <smart.video.Video.Video at 0x1162603f190>,\n",
       " <smart.video.Video.Video at 0x1162603f1f0>,\n",
       " <smart.video.Video.Video at 0x1162603f250>,\n",
       " <smart.video.Video.Video at 0x1162603f340>,\n",
       " <smart.video.Video.Video at 0x1162603f100>,\n",
       " <smart.video.Video.Video at 0x1162603f400>,\n",
       " <smart.video.Video.Video at 0x1162603f460>,\n",
       " <smart.video.Video.Video at 0x1162603f3d0>,\n",
       " <smart.video.Video.Video at 0x1162603f4c0>,\n",
       " <smart.video.Video.Video at 0x1162603f520>,\n",
       " <smart.video.Video.Video at 0x1162603f490>,\n",
       " <smart.video.Video.Video at 0x1162603f610>,\n",
       " <smart.video.Video.Video at 0x1162603f5b0>,\n",
       " <smart.video.Video.Video at 0x1162603f6d0>,\n",
       " <smart.video.Video.Video at 0x1162603f700>,\n",
       " <smart.video.Video.Video at 0x1162603f670>,\n",
       " <smart.video.Video.Video at 0x1162603f790>,\n",
       " <smart.video.Video.Video at 0x1162603f7f0>,\n",
       " <smart.video.Video.Video at 0x1162603f850>,\n",
       " <smart.video.Video.Video at 0x1162603f8b0>,\n",
       " <smart.video.Video.Video at 0x1162603f910>,\n",
       " <smart.video.Video.Video at 0x1162603f970>,\n",
       " <smart.video.Video.Video at 0x1162603fa30>,\n",
       " <smart.video.Video.Video at 0x1162603fa00>,\n",
       " <smart.video.Video.Video at 0x1162603fb20>,\n",
       " <smart.video.Video.Video at 0x1162603fa90>,\n",
       " <smart.video.Video.Video at 0x1162603fb50>,\n",
       " <smart.video.Video.Video at 0x1162603fbb0>,\n",
       " <smart.video.Video.Video at 0x1162603fc10>,\n",
       " <smart.video.Video.Video at 0x1162603fc70>,\n",
       " <smart.video.Video.Video at 0x1162603fcd0>,\n",
       " <smart.video.Video.Video at 0x1162603fd30>,\n",
       " <smart.video.Video.Video at 0x1162603fe20>,\n",
       " <smart.video.Video.Video at 0x1162603fdc0>,\n",
       " <smart.video.Video.Video at 0x1162603fe50>,\n",
       " <smart.video.Video.Video at 0x1162603feb0>,\n",
       " <smart.video.Video.Video at 0x1162603ffa0>,\n",
       " <smart.video.Video.Video at 0x1162603ffd0>,\n",
       " <smart.video.Video.Video at 0x11624b84d00>,\n",
       " <smart.video.Video.Video at 0x1162603f370>,\n",
       " <smart.video.Video.Video at 0x116260440d0>,\n",
       " <smart.video.Video.Video at 0x11626044130>,\n",
       " <smart.video.Video.Video at 0x11626044190>,\n",
       " <smart.video.Video.Video at 0x11626044250>,\n",
       " <smart.video.Video.Video at 0x116260441f0>,\n",
       " <smart.video.Video.Video at 0x11626044340>,\n",
       " <smart.video.Video.Video at 0x11626044220>,\n",
       " <smart.video.Video.Video at 0x116260442e0>,\n",
       " <smart.video.Video.Video at 0x11626044310>,\n",
       " <smart.video.Video.Video at 0x11626044400>,\n",
       " <smart.video.Video.Video at 0x11626044460>,\n",
       " <smart.video.Video.Video at 0x116260444c0>,\n",
       " <smart.video.Video.Video at 0x11626044520>,\n",
       " <smart.video.Video.Video at 0x11626044580>,\n",
       " <smart.video.Video.Video at 0x116260445e0>,\n",
       " <smart.video.Video.Video at 0x11626044640>,\n",
       " <smart.video.Video.Video at 0x116260446a0>,\n",
       " <smart.video.Video.Video at 0x11626044700>,\n",
       " <smart.video.Video.Video at 0x11626044760>,\n",
       " <smart.video.Video.Video at 0x116260447c0>,\n",
       " <smart.video.Video.Video at 0x11626044820>,\n",
       " <smart.video.Video.Video at 0x11626044880>,\n",
       " <smart.video.Video.Video at 0x116260448e0>,\n",
       " <smart.video.Video.Video at 0x11626044940>,\n",
       " <smart.video.Video.Video at 0x116260449a0>,\n",
       " <smart.video.Video.Video at 0x11626044a00>,\n",
       " <smart.video.Video.Video at 0x11626044a60>,\n",
       " <smart.video.Video.Video at 0x11626044ac0>,\n",
       " <smart.video.Video.Video at 0x11626044b20>,\n",
       " <smart.video.Video.Video at 0x11626044b80>,\n",
       " <smart.video.Video.Video at 0x11626044be0>,\n",
       " <smart.video.Video.Video at 0x11626044c40>,\n",
       " <smart.video.Video.Video at 0x11626044ca0>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output sans label encoder\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer output y en one hot vector\n",
    "- 0: coup droit\n",
    "- 1: déplacement\n",
    "- 2: revers\n",
    "- 3: service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_y = np.unique(y)\n",
    "output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37500"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résolution des images\n",
    "input_shape_model = list_videos[0].frames.shape[0] * list_videos[0].frames.shape[1] * list_videos[0].frames.shape[2]\n",
    "input_shape_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(list_videos) * 0.8)\n",
    "test_size = len(list_videos) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 171, 43, 43)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split video train, test\n",
    "random.seed(42)\n",
    "vids_train = random.sample(list_videos, k = train_size)\n",
    "vids_test = [vid for vid in list_videos if vid not in vids_train]\n",
    "y_train = [y[i] for i in range(len(y)) if list_videos[i] in vids_train]\n",
    "y_test = [y[i] for i in range(len(y)) if list_videos[i] in vids_test]\n",
    "paths_test = [all_paths[i] for i in range(len(all_paths)) if list_videos[i] in vids_test]\n",
    "len(vids_train), len(y_train), len(vids_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img/JBas\\\\coup droit\\\\1980-2563441\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\1980-2563523\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\42698-4288095\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\a36r805\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\Alcaraz_Sinner270\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\AS_13416\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\AS_22373\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\AS_30502\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\AS_37288\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\AS_40159\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\car0001-0342253\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\car5493-5847185\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\na0201977\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\uopc1041\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\uopc1683\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\uopc339\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\a36r1216\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\a36r1713\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\a36r172\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\a36r257\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\a36r339\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\AS_13292\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\AS_40133\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\car5936-6390437\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\ivjs985\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\na0201125\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\na0201446\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\na0201578\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\na0201831\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\uopc1067\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\uopc227\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\uopc304\\\\images',\n",
       " 'img/JBas\\\\revers\\\\a36r1276\\\\images',\n",
       " 'img/JBas\\\\revers\\\\AS_24472\\\\images',\n",
       " 'img/JBas\\\\revers\\\\AS_35566\\\\images',\n",
       " 'img/JBas\\\\revers\\\\car2491-2852287\\\\images',\n",
       " 'img/JBas\\\\revers\\\\clip_usopen896\\\\images',\n",
       " 'img/JBas\\\\revers\\\\na02011281\\\\images',\n",
       " 'img/JBas\\\\revers\\\\na02011743\\\\images',\n",
       " 'img/JBas\\\\service\\\\AS_34155\\\\images',\n",
       " 'img/JBas\\\\service\\\\car0001-0342180\\\\images',\n",
       " 'img/JBas\\\\service\\\\car2491-2852108\\\\images',\n",
       " 'img/JBas\\\\service\\\\car5493-5847116\\\\images']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_train, dtype=int)\n",
    "y_test = np.array(y_test, dtype=int)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split input X en train, test set\n",
    "X_train = np.zeros((train_size, 50*50*15), dtype=int)\n",
    "for i, vid in enumerate(vids_train):\n",
    "    seq_img = vid.frames.flatten()\n",
    "    X_train[i] = seq_img\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.zeros((test_size, 50*50*15), dtype=int)\n",
    "for i, vid in enumerate(vids_test):\n",
    "    seq_img = vid.frames.flatten()\n",
    "    X_test[i] = seq_img\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle de réseau de neurones avec classification multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 16)                600016    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 611,508\n",
      "Trainable params: 611,508\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1234) # for consistent results\n",
    "model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape = input_shape_model), # 50*50 * 15 = 37500\n",
    "        Dense(units=16, activation=\"relu\"),\n",
    "        Dense(units=32, activation=\"relu\"),\n",
    "        Dense(units=64, activation=\"sigmoid\"),\n",
    "        Dense(units=128, activation=\"relu\"),\n",
    "        Dense(units=len(output_y), activation=\"softmax\"),\n",
    "    ]\n",
    ")          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'checkpoints/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4128 - accuracy: 0.3750\n",
      "Epoch 1: val_loss improved from inf to 2.71367, saving model to checkpoints\\Weights-001--2.71367.hdf5\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.2540 - accuracy: 0.3897 - val_loss: 2.7137 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0991 - accuracy: 0.3438\n",
      "Epoch 2: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0726 - accuracy: 0.4853 - val_loss: 3.5563 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0235 - accuracy: 0.4688\n",
      "Epoch 3: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9866 - accuracy: 0.4632 - val_loss: 4.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9764 - accuracy: 0.4375\n",
      "Epoch 4: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9117 - accuracy: 0.5882 - val_loss: 4.1932 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.8690 - accuracy: 0.6562\n",
      "Epoch 5: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7709 - accuracy: 0.7721 - val_loss: 4.3193 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6359 - accuracy: 0.9062\n",
      "Epoch 6: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5988 - accuracy: 0.8971 - val_loss: 4.4093 - val_accuracy: 0.0571\n",
      "Epoch 7/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5124 - accuracy: 0.9688\n",
      "Epoch 7: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4362 - accuracy: 0.9779 - val_loss: 4.5297 - val_accuracy: 0.0286\n",
      "Epoch 8/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3128 - accuracy: 0.9688\n",
      "Epoch 8: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2700 - accuracy: 0.9926 - val_loss: 4.7635 - val_accuracy: 0.0571\n",
      "Epoch 9/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1723 - accuracy: 1.0000\n",
      "Epoch 9: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1578 - accuracy: 1.0000 - val_loss: 4.8939 - val_accuracy: 0.0286\n",
      "Epoch 10/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1107 - accuracy: 1.0000\n",
      "Epoch 10: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0941 - accuracy: 1.0000 - val_loss: 5.0910 - val_accuracy: 0.0286\n",
      "Epoch 11/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0566 - accuracy: 1.0000\n",
      "Epoch 11: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 5.2618 - val_accuracy: 0.0857\n",
      "Epoch 12/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 12: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 5.4542 - val_accuracy: 0.0571\n",
      "Epoch 13/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 13: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 5.6358 - val_accuracy: 0.0571\n",
      "Epoch 14/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 14: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 5.7756 - val_accuracy: 0.0571\n",
      "Epoch 15/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 15: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 5.8426 - val_accuracy: 0.0571\n",
      "Epoch 16/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 16: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 5.8608 - val_accuracy: 0.0571\n",
      "Epoch 17/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 17: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 5.9116 - val_accuracy: 0.0571\n",
      "Epoch 18/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 18: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 5.9734 - val_accuracy: 0.0571\n",
      "Epoch 19/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 19: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 6.0534 - val_accuracy: 0.0571\n",
      "Epoch 20/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 20: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 6.1434 - val_accuracy: 0.0571\n",
      "Epoch 21/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 21: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 6.1974 - val_accuracy: 0.0571\n",
      "Epoch 22/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 22: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 6.2288 - val_accuracy: 0.0571\n",
      "Epoch 23/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 23: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 6.2474 - val_accuracy: 0.0571\n",
      "Epoch 24/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 24: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 6.2687 - val_accuracy: 0.0571\n",
      "Epoch 25/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 25: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 6.2948 - val_accuracy: 0.0571\n",
      "Epoch 26/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 26: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 6.3286 - val_accuracy: 0.0571\n",
      "Epoch 27/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 27: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 6.3594 - val_accuracy: 0.0571\n",
      "Epoch 28/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 28: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 6.3782 - val_accuracy: 0.0571\n",
      "Epoch 29/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 29: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 6.4058 - val_accuracy: 0.0571\n",
      "Epoch 30/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 30: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 6.4368 - val_accuracy: 0.0571\n",
      "Epoch 31/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 31: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 6.4686 - val_accuracy: 0.0571\n",
      "Epoch 32/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 32: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.4952 - val_accuracy: 0.0571\n",
      "Epoch 33/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 33: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.5237 - val_accuracy: 0.0571\n",
      "Epoch 34/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 34: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.5535 - val_accuracy: 0.0571\n",
      "Epoch 35/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 35: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.5655 - val_accuracy: 0.0571\n",
      "Epoch 36/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 36: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.5804 - val_accuracy: 0.0571\n",
      "Epoch 37/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 37: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.5852 - val_accuracy: 0.0571\n",
      "Epoch 38/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 38: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.5472 - val_accuracy: 0.0571\n",
      "Epoch 39/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 39: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.5706 - val_accuracy: 0.0571\n",
      "Epoch 40/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 40: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.5992 - val_accuracy: 0.0571\n",
      "Epoch 41/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 41: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.5999 - val_accuracy: 0.0571\n",
      "Epoch 42/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 42: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.6131 - val_accuracy: 0.0571\n",
      "Epoch 43/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 43: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.6365 - val_accuracy: 0.0571\n",
      "Epoch 44/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 44: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.6740 - val_accuracy: 0.0571\n",
      "Epoch 45/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 45: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.1935e-04 - accuracy: 1.0000 - val_loss: 6.7309 - val_accuracy: 0.0571\n",
      "Epoch 46/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3866e-04 - accuracy: 1.0000\n",
      "Epoch 46: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.3407e-04 - accuracy: 1.0000 - val_loss: 6.7843 - val_accuracy: 0.0571\n",
      "Epoch 47/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.6914e-04 - accuracy: 1.0000\n",
      "Epoch 47: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 7.5559e-04 - accuracy: 1.0000 - val_loss: 6.8232 - val_accuracy: 0.0571\n",
      "Epoch 48/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.4194e-04 - accuracy: 1.0000\n",
      "Epoch 48: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 6.8317e-04 - accuracy: 1.0000 - val_loss: 6.8877 - val_accuracy: 0.0571\n",
      "Epoch 49/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7607e-04 - accuracy: 1.0000\n",
      "Epoch 49: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.1928e-04 - accuracy: 1.0000 - val_loss: 6.9479 - val_accuracy: 0.0571\n",
      "Epoch 50/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1225e-04 - accuracy: 1.0000\n",
      "Epoch 50: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.6227e-04 - accuracy: 1.0000 - val_loss: 7.0150 - val_accuracy: 0.0571\n",
      "Epoch 51/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.2104e-04 - accuracy: 1.0000\n",
      "Epoch 51: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.1402e-04 - accuracy: 1.0000 - val_loss: 7.0701 - val_accuracy: 0.0571\n",
      "Epoch 52/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0030e-04 - accuracy: 1.0000\n",
      "Epoch 52: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.6912e-04 - accuracy: 1.0000 - val_loss: 7.1251 - val_accuracy: 0.0571\n",
      "Epoch 53/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9325e-04 - accuracy: 1.0000\n",
      "Epoch 53: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.3067e-04 - accuracy: 1.0000 - val_loss: 7.1847 - val_accuracy: 0.0571\n",
      "Epoch 54/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8738e-04 - accuracy: 1.0000\n",
      "Epoch 54: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.9744e-04 - accuracy: 1.0000 - val_loss: 7.2339 - val_accuracy: 0.0571\n",
      "Epoch 55/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8418e-04 - accuracy: 1.0000\n",
      "Epoch 55: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.6770e-04 - accuracy: 1.0000 - val_loss: 7.2895 - val_accuracy: 0.0571\n",
      "Epoch 56/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4728e-04 - accuracy: 1.0000\n",
      "Epoch 56: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.4129e-04 - accuracy: 1.0000 - val_loss: 7.3485 - val_accuracy: 0.0571\n",
      "Epoch 57/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1246e-04 - accuracy: 1.0000\n",
      "Epoch 57: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.1788e-04 - accuracy: 1.0000 - val_loss: 7.3999 - val_accuracy: 0.0571\n",
      "Epoch 58/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1242e-04 - accuracy: 1.0000\n",
      "Epoch 58: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.9742e-04 - accuracy: 1.0000 - val_loss: 7.4488 - val_accuracy: 0.0571\n",
      "Epoch 59/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8924e-04 - accuracy: 1.0000\n",
      "Epoch 59: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.7860e-04 - accuracy: 1.0000 - val_loss: 7.5050 - val_accuracy: 0.0571\n",
      "Epoch 60/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0732e-04 - accuracy: 1.0000\n",
      "Epoch 60: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.6216e-04 - accuracy: 1.0000 - val_loss: 7.5549 - val_accuracy: 0.0571\n",
      "Epoch 61/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5175e-04 - accuracy: 1.0000\n",
      "Epoch 61: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.4697e-04 - accuracy: 1.0000 - val_loss: 7.6068 - val_accuracy: 0.0571\n",
      "Epoch 62/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4558e-04 - accuracy: 1.0000\n",
      "Epoch 62: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.3315e-04 - accuracy: 1.0000 - val_loss: 7.6525 - val_accuracy: 0.0571\n",
      "Epoch 63/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2171e-04 - accuracy: 1.0000\n",
      "Epoch 63: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.2035e-04 - accuracy: 1.0000 - val_loss: 7.6873 - val_accuracy: 0.0571\n",
      "Epoch 64/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2227e-04 - accuracy: 1.0000\n",
      "Epoch 64: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.0908e-04 - accuracy: 1.0000 - val_loss: 7.7247 - val_accuracy: 0.0571\n",
      "Epoch 65/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0719e-04 - accuracy: 1.0000\n",
      "Epoch 65: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.9863e-04 - accuracy: 1.0000 - val_loss: 7.7707 - val_accuracy: 0.0571\n",
      "Epoch 66/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3516e-04 - accuracy: 1.0000\n",
      "Epoch 66: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.8910e-04 - accuracy: 1.0000 - val_loss: 7.8192 - val_accuracy: 0.0571\n",
      "Epoch 67/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7221e-04 - accuracy: 1.0000\n",
      "Epoch 67: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.8019e-04 - accuracy: 1.0000 - val_loss: 7.8697 - val_accuracy: 0.0571\n",
      "Epoch 68/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7119e-04 - accuracy: 1.0000\n",
      "Epoch 68: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.7199e-04 - accuracy: 1.0000 - val_loss: 7.9196 - val_accuracy: 0.0571\n",
      "Epoch 69/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6315e-04 - accuracy: 1.0000\n",
      "Epoch 69: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.6454e-04 - accuracy: 1.0000 - val_loss: 7.9638 - val_accuracy: 0.0571\n",
      "Epoch 70/70\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7216e-04 - accuracy: 1.0000\n",
      "Epoch 70: val_loss did not improve from 2.71367\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.5763e-04 - accuracy: 1.0000 - val_loss: 7.9940 - val_accuracy: 0.0571\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = Adam(learning_rate=0.001), # 'Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 70,\n",
    "    batch_size = 32, # données transmises pour une session\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 3.7356 - accuracy: 0.3488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.73563551902771, 0.3488371968269348]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.31466552e-03, 9.80816066e-01, 1.58282015e-02, 4.09925342e-05],\n",
       "       [1.35716632e-01, 3.96943390e-02, 8.24380934e-01, 2.08058686e-04],\n",
       "       [1.80883519e-02, 9.81426179e-01, 4.58119554e-04, 2.73225451e-05],\n",
       "       [2.36354047e-03, 9.97216702e-01, 4.06670762e-04, 1.30653252e-05],\n",
       "       [9.60909296e-03, 9.87393260e-01, 2.95358594e-03, 4.40086988e-05],\n",
       "       [1.24936458e-02, 9.75139022e-01, 1.23040443e-02, 6.33372983e-05],\n",
       "       [8.57563674e-01, 9.75261815e-03, 1.32515788e-01, 1.67973907e-04],\n",
       "       [9.99868155e-01, 1.04768485e-04, 2.35154621e-05, 3.62156675e-06],\n",
       "       [1.63514761e-03, 9.91771996e-01, 6.56424277e-03, 2.86319755e-05],\n",
       "       [8.57678428e-02, 9.13446844e-01, 7.34232424e-04, 5.10491082e-05],\n",
       "       [9.72295284e-01, 8.00719298e-03, 1.96219534e-02, 7.55474393e-05],\n",
       "       [9.99745905e-01, 2.15173990e-04, 3.46444904e-05, 4.21551840e-06],\n",
       "       [2.72275734e-04, 9.99612033e-01, 1.11248366e-04, 4.55079817e-06],\n",
       "       [6.20603681e-01, 2.95015305e-01, 8.40738118e-02, 3.07241862e-04],\n",
       "       [7.15278415e-03, 9.92571533e-01, 2.58158107e-04, 1.74882753e-05],\n",
       "       [9.93283272e-01, 6.14494737e-03, 5.51080622e-04, 2.07124122e-05],\n",
       "       [2.09256280e-02, 9.19722021e-01, 5.92467785e-02, 1.05629013e-04],\n",
       "       [2.14403059e-04, 9.99533653e-01, 2.46303796e-04, 5.73389389e-06],\n",
       "       [3.12387347e-01, 4.63353634e-01, 2.23926216e-01, 3.32875381e-04],\n",
       "       [9.17742133e-01, 7.91638494e-02, 3.02788895e-03, 6.61562080e-05],\n",
       "       [2.91822497e-02, 8.76420677e-01, 9.42556411e-02, 1.41463097e-04],\n",
       "       [9.92613077e-01, 5.35996491e-03, 1.99921615e-03, 2.78297448e-05],\n",
       "       [1.66076483e-04, 1.41931965e-03, 9.98404801e-01, 9.87969270e-06],\n",
       "       [9.48153317e-01, 2.67256107e-02, 2.46534981e-02, 4.67614009e-04],\n",
       "       [7.63826029e-05, 9.99892950e-01, 2.86915383e-05, 1.95437474e-06],\n",
       "       [3.52452807e-02, 8.66554856e-01, 9.80310068e-02, 1.68896833e-04],\n",
       "       [9.95411098e-01, 4.11185296e-03, 4.57924878e-04, 1.91088111e-05],\n",
       "       [7.78101921e-01, 9.38051715e-02, 1.27842695e-01, 2.50168872e-04],\n",
       "       [9.56858039e-01, 4.25378829e-02, 5.61953057e-04, 4.20882425e-05],\n",
       "       [9.64445829e-01, 2.93048918e-02, 6.18257420e-03, 6.66971100e-05],\n",
       "       [4.90676286e-03, 9.57042515e-01, 3.79882269e-02, 6.25245739e-05],\n",
       "       [7.95597792e-01, 3.90864275e-02, 1.65098280e-01, 2.17495486e-04],\n",
       "       [1.18944474e-01, 9.93168727e-03, 8.70899618e-01, 2.24276911e-04],\n",
       "       [4.97932918e-03, 4.93995458e-01, 5.00879645e-01, 1.45574581e-04],\n",
       "       [8.37413013e-01, 1.49321169e-01, 1.31135359e-02, 1.52293855e-04],\n",
       "       [9.87078190e-01, 9.40015831e-04, 1.19281486e-02, 5.37362575e-05],\n",
       "       [9.98779476e-01, 6.05218054e-04, 6.01260632e-04, 1.39907115e-05],\n",
       "       [9.99095678e-01, 7.78260059e-04, 1.16351388e-04, 9.67287269e-06],\n",
       "       [4.97740833e-03, 9.94437933e-01, 5.63666865e-04, 2.09914124e-05],\n",
       "       [9.97940719e-01, 6.84161321e-04, 1.34899281e-03, 2.60740835e-05],\n",
       "       [2.43244991e-01, 7.19949603e-01, 3.65635902e-02, 2.41843241e-04],\n",
       "       [1.22192413e-01, 8.74404192e-01, 3.31167574e-03, 9.17552534e-05],\n",
       "       [9.99799669e-01, 1.66757178e-04, 2.99473686e-05, 3.66454037e-06]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:  [1 2 1 1 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 2 0 1 1 0 0 0 0 1 0 2 2 0 0 0\n",
      " 0 1 0 1 1 0]\n",
      "True labels:       [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(pred, axis=1)\n",
    "print(\"Predicted labels: \", y_pred)\n",
    "print(\"True labels:      \", y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy: $17 / 43$ ($39.53 \\%$)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseaux de neurones convolutifs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prises des frames et des vidéos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_videos_cnn = []\n",
    "y_cnn = []\n",
    "for dirpath, dirnames, _ in os.walk(path_dataset):\n",
    "    for dir_type in dirnames:\n",
    "        \n",
    "        path_fol = os.path.join(dirpath, dir_type)\n",
    "        for file in os.listdir(path_fol):\n",
    "            path_fol_img = os.path.join(path_fol, file)\n",
    "            if os.path.isdir(path_fol_img) and file == 'images':\n",
    "                frames = []\n",
    "                for file_img in os.listdir(path_fol_img):\n",
    "                    path_img = os.path.join(path_fol_img, file_img)\n",
    "                    img_obj = Image.load_image(cv2.IMREAD_COLOR, path_img)\n",
    "                    img = img_obj.img\n",
    "                    frames.append(img)\t\n",
    "                if (len(frames) == 15):\n",
    "                    output_res = path_img.split('\\\\')[1]\n",
    "                    vid = Video.read_video_from_frames(frames)\n",
    "                    list_videos_cnn.append(vid)\n",
    "                    y_cnn.append(output_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_videos_cnn[0].frames.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer output y en one hot vector\n",
    "- 0: coup droit\n",
    "- 1: déplacement\n",
    "- 2: revers\n",
    "- 3: service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cnn = encoder.fit_transform(y_cnn)\n",
    "y_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_y = np.unique(y_cnn)\n",
    "output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_videos_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(list_videos_cnn) * 0.8)\n",
    "test_size = len(list_videos_cnn) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 171, 43, 43)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split video train, test\n",
    "random.seed(42)\n",
    "vids_train_cnn = random.sample(list_videos_cnn, k = train_size)\n",
    "vids_test_cnn = [vid for vid in list_videos_cnn if vid not in vids_train_cnn]\n",
    "y_train_cnn = [y_cnn[i] for i in range(len(y_cnn)) if list_videos_cnn[i] in vids_train_cnn]\n",
    "y_test_cnn = [y_cnn[i] for i in range(len(y_cnn)) if list_videos_cnn[i] in vids_test_cnn]\n",
    "len(vids_train_cnn), len(y_train_cnn), len(vids_test_cnn), len(y_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cnn = np.array(y_train_cnn, dtype=int)\n",
    "y_test_cnn = np.array(y_test_cnn, dtype=int)\n",
    "y_train_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 50, 750, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split input X en train, test set\n",
    "X_train_cnn = np.zeros((train_size, 50, 15*50, 3), dtype=int)\n",
    "for i, vid in enumerate(vids_train_cnn):\n",
    "    for j, frame in enumerate(vid.frames):\n",
    "        X_train_cnn[i, :, 50*j:50*(j+1), :] = frame\n",
    "X_train_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 50, 750, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cnn = np.zeros((test_size, 50, 15*50, 3), dtype=int)\n",
    "for i, vid in enumerate(vids_test_cnn):\n",
    "    for j, frame in enumerate(vid.frames):\n",
    "        X_test_cnn[i, :, 50*j:50*(j+1), :] = frame\n",
    "X_test_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 750, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape_cnn = X_train_cnn.shape[1:]\n",
    "input_shape_cnn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle de réseau de neurones convolutifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 748, 16)       448       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 748, 16)      64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 374, 16)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 374, 16)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 22, 372, 32)       4640      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 22, 372, 32)      128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 11, 186, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 11, 186, 32)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 184, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 9, 184, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 92, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 92, 64)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23552)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               3014784   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,039,332\n",
      "Trainable params: 3,039,108\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape = input_shape_cnn), # 50, 15*50, 3\n",
    "        Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(units=128, activation=\"relu\"),\n",
    "        Dense(units=len(output_y), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'checkpoints/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 7.7146 - accuracy: 0.7132\n",
      "Epoch 1: val_loss improved from inf to 44.49462, saving model to checkpoints\\Weights-001--44.49462.hdf5\n",
      "5/5 [==============================] - 2s 282ms/step - loss: 7.7146 - accuracy: 0.7132 - val_loss: 44.4946 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.8054 - accuracy: 0.7721\n",
      "Epoch 2: val_loss improved from 44.49462 to 37.66714, saving model to checkpoints\\Weights-002--37.66714.hdf5\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 1.8054 - accuracy: 0.7721 - val_loss: 37.6671 - val_accuracy: 0.2857\n",
      "Epoch 3/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.9265\n",
      "Epoch 3: val_loss improved from 37.66714 to 28.19355, saving model to checkpoints\\Weights-003--28.19355.hdf5\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.2365 - accuracy: 0.9265 - val_loss: 28.1935 - val_accuracy: 0.1143\n",
      "Epoch 4/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8824 - accuracy: 0.8603\n",
      "Epoch 4: val_loss improved from 28.19355 to 22.24244, saving model to checkpoints\\Weights-004--22.24244.hdf5\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.8824 - accuracy: 0.8603 - val_loss: 22.2424 - val_accuracy: 0.1429\n",
      "Epoch 5/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9779\n",
      "Epoch 5: val_loss did not improve from 22.24244\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.0481 - accuracy: 0.9779 - val_loss: 24.5601 - val_accuracy: 0.2286\n",
      "Epoch 6/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9706\n",
      "Epoch 6: val_loss did not improve from 22.24244\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.0700 - accuracy: 0.9706 - val_loss: 25.9545 - val_accuracy: 0.2286\n",
      "Epoch 7/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 7: val_loss did not improve from 22.24244\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 25.3717 - val_accuracy: 0.2286\n",
      "Epoch 8/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 8: val_loss did not improve from 22.24244\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 24.4597 - val_accuracy: 0.2000\n",
      "Epoch 9/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8759 - accuracy: 0.8824\n",
      "Epoch 9: val_loss improved from 22.24244 to 17.63377, saving model to checkpoints\\Weights-009--17.63377.hdf5\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.8759 - accuracy: 0.8824 - val_loss: 17.6338 - val_accuracy: 0.2000\n",
      "Epoch 10/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5207 - accuracy: 0.9265\n",
      "Epoch 10: val_loss improved from 17.63377 to 11.38504, saving model to checkpoints\\Weights-010--11.38504.hdf5\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.5207 - accuracy: 0.9265 - val_loss: 11.3850 - val_accuracy: 0.1429\n",
      "Epoch 11/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 0.9853\n",
      "Epoch 11: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.1167 - accuracy: 0.9853 - val_loss: 11.7394 - val_accuracy: 0.1714\n",
      "Epoch 12/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9338\n",
      "Epoch 12: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.2408 - accuracy: 0.9338 - val_loss: 13.7603 - val_accuracy: 0.0571\n",
      "Epoch 13/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.9485\n",
      "Epoch 13: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3068 - accuracy: 0.9485 - val_loss: 15.4749 - val_accuracy: 0.1714\n",
      "Epoch 14/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2762 - accuracy: 0.9559\n",
      "Epoch 14: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.2762 - accuracy: 0.9559 - val_loss: 13.1066 - val_accuracy: 0.1714\n",
      "Epoch 15/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 15: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 13.6729 - val_accuracy: 0.1714\n",
      "Epoch 16/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.2681e-04 - accuracy: 1.0000\n",
      "Epoch 16: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 8.2681e-04 - accuracy: 1.0000 - val_loss: 13.9615 - val_accuracy: 0.1714\n",
      "Epoch 17/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.9244e-04 - accuracy: 1.0000\n",
      "Epoch 17: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 1.9244e-04 - accuracy: 1.0000 - val_loss: 14.4219 - val_accuracy: 0.1429\n",
      "Epoch 18/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000  \n",
      "Epoch 18: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 14.7618 - val_accuracy: 0.1429\n",
      "Epoch 19/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 19: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 15.5322 - val_accuracy: 0.1429\n",
      "Epoch 20/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9926    \n",
      "Epoch 20: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0079 - accuracy: 0.9926 - val_loss: 32.2021 - val_accuracy: 0.2857\n",
      "Epoch 21/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.9611 - accuracy: 0.7868\n",
      "Epoch 21: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 2.9611 - accuracy: 0.7868 - val_loss: 15.3277 - val_accuracy: 0.1714\n",
      "Epoch 22/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9779\n",
      "Epoch 22: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0516 - accuracy: 0.9779 - val_loss: 16.0189 - val_accuracy: 0.1429\n",
      "Epoch 23/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 23: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 16.8703 - val_accuracy: 0.1429\n",
      "Epoch 24/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.6293e-04 - accuracy: 1.0000\n",
      "Epoch 24: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 2.6293e-04 - accuracy: 1.0000 - val_loss: 17.5827 - val_accuracy: 0.1143\n",
      "Epoch 25/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2440e-04 - accuracy: 1.0000\n",
      "Epoch 25: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 2.2440e-04 - accuracy: 1.0000 - val_loss: 18.3885 - val_accuracy: 0.0857\n",
      "Epoch 26/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.1733e-04 - accuracy: 1.0000\n",
      "Epoch 26: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 1.1733e-04 - accuracy: 1.0000 - val_loss: 19.1863 - val_accuracy: 0.0571\n",
      "Epoch 27/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9926\n",
      "Epoch 27: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0159 - accuracy: 0.9926 - val_loss: 25.8009 - val_accuracy: 0.0286\n",
      "Epoch 28/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 4.6527e-04 - accuracy: 1.0000\n",
      "Epoch 28: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 4.6527e-04 - accuracy: 1.0000 - val_loss: 26.6707 - val_accuracy: 0.0286\n",
      "Epoch 29/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 5.5595e-04 - accuracy: 1.0000\n",
      "Epoch 29: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 5.5595e-04 - accuracy: 1.0000 - val_loss: 27.9486 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.2596e-04 - accuracy: 1.0000\n",
      "Epoch 30: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 1.2596e-04 - accuracy: 1.0000 - val_loss: 28.5769 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.7365e-05 - accuracy: 1.0000\n",
      "Epoch 31: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 2.7365e-05 - accuracy: 1.0000 - val_loss: 29.3216 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.9709e-04 - accuracy: 1.0000\n",
      "Epoch 32: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 3.9709e-04 - accuracy: 1.0000 - val_loss: 30.1982 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.4219e-04 - accuracy: 1.0000\n",
      "Epoch 33: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 3.4219e-04 - accuracy: 1.0000 - val_loss: 29.0162 - val_accuracy: 0.0286\n",
      "Epoch 34/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 4.1420e-05 - accuracy: 1.0000\n",
      "Epoch 34: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 4.1420e-05 - accuracy: 1.0000 - val_loss: 29.8683 - val_accuracy: 0.0286\n",
      "Epoch 35/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 9.5449e-05 - accuracy: 1.0000\n",
      "Epoch 35: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 9.5449e-05 - accuracy: 1.0000 - val_loss: 31.1653 - val_accuracy: 0.0286\n",
      "Epoch 36/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.8488e-05 - accuracy: 1.0000\n",
      "Epoch 36: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 8.8488e-05 - accuracy: 1.0000 - val_loss: 31.9739 - val_accuracy: 0.0286\n",
      "Epoch 37/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 9.5512e-05 - accuracy: 1.0000\n",
      "Epoch 37: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 9.5512e-05 - accuracy: 1.0000 - val_loss: 32.3226 - val_accuracy: 0.0286\n",
      "Epoch 38/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.4957e-06 - accuracy: 1.0000\n",
      "Epoch 38: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 8.4957e-06 - accuracy: 1.0000 - val_loss: 33.0305 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 4.1950e-05 - accuracy: 1.0000\n",
      "Epoch 39: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 4.1950e-05 - accuracy: 1.0000 - val_loss: 33.5070 - val_accuracy: 0.0286\n",
      "Epoch 40/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.4196e-05 - accuracy: 1.0000\n",
      "Epoch 40: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 2.4196e-05 - accuracy: 1.0000 - val_loss: 34.2246 - val_accuracy: 0.0286\n",
      "Epoch 41/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.3300e-05 - accuracy: 1.0000\n",
      "Epoch 41: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 1.3300e-05 - accuracy: 1.0000 - val_loss: 35.0229 - val_accuracy: 0.0286\n",
      "Epoch 42/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 7.2140e-06 - accuracy: 1.0000\n",
      "Epoch 42: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 7.2140e-06 - accuracy: 1.0000 - val_loss: 36.0477 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.2724e-05 - accuracy: 1.0000\n",
      "Epoch 43: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 1.2724e-05 - accuracy: 1.0000 - val_loss: 36.8483 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 4.0408e-05 - accuracy: 1.0000\n",
      "Epoch 44: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 4.0408e-05 - accuracy: 1.0000 - val_loss: 38.6878 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.7103e-06 - accuracy: 1.0000\n",
      "Epoch 45: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 8.7103e-06 - accuracy: 1.0000 - val_loss: 39.1003 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 6.5887e-05 - accuracy: 1.0000\n",
      "Epoch 46: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 6.5887e-05 - accuracy: 1.0000 - val_loss: 39.1417 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.2098e-06 - accuracy: 1.0000\n",
      "Epoch 47: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 3.2098e-06 - accuracy: 1.0000 - val_loss: 39.7463 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9926  \n",
      "Epoch 48: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.0298 - accuracy: 0.9926 - val_loss: 39.5991 - val_accuracy: 0.0857\n",
      "Epoch 49/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000    \n",
      "Epoch 49: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 39.1945 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 6.5410e-04 - accuracy: 1.0000\n",
      "Epoch 50: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 6.5410e-04 - accuracy: 1.0000 - val_loss: 41.9626 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9779\n",
      "Epoch 51: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.0911 - accuracy: 0.9779 - val_loss: 34.8818 - val_accuracy: 0.0286\n",
      "Epoch 52/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9853\n",
      "Epoch 52: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.0248 - accuracy: 0.9853 - val_loss: 33.2204 - val_accuracy: 0.0571\n",
      "Epoch 53/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9853\n",
      "Epoch 53: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.0163 - accuracy: 0.9853 - val_loss: 35.5547 - val_accuracy: 0.0857\n",
      "Epoch 54/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9926\n",
      "Epoch 54: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.0955 - accuracy: 0.9926 - val_loss: 39.2995 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.7265e-04 - accuracy: 1.0000\n",
      "Epoch 55: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 2.7265e-04 - accuracy: 1.0000 - val_loss: 39.6088 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.7393e-04 - accuracy: 1.0000\n",
      "Epoch 56: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 1.7393e-04 - accuracy: 1.0000 - val_loss: 40.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.0850e-05 - accuracy: 1.0000\n",
      "Epoch 57: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 1.0850e-05 - accuracy: 1.0000 - val_loss: 40.5400 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 6.8979e-05 - accuracy: 1.0000\n",
      "Epoch 58: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 6.8979e-05 - accuracy: 1.0000 - val_loss: 40.8647 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.8519e-06 - accuracy: 1.0000\n",
      "Epoch 59: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 3.8519e-06 - accuracy: 1.0000 - val_loss: 41.3039 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.1737e-05 - accuracy: 1.0000\n",
      "Epoch 60: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 1.1737e-05 - accuracy: 1.0000 - val_loss: 41.6034 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 5.7921e-05 - accuracy: 1.0000\n",
      "Epoch 61: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 5.7921e-05 - accuracy: 1.0000 - val_loss: 41.9050 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.7224e-06 - accuracy: 1.0000\n",
      "Epoch 62: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 2.7224e-06 - accuracy: 1.0000 - val_loss: 42.3048 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.8044e-05 - accuracy: 1.0000\n",
      "Epoch 63: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 2.8044e-05 - accuracy: 1.0000 - val_loss: 42.5799 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.4945e-06 - accuracy: 1.0000\n",
      "Epoch 64: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 1.4945e-06 - accuracy: 1.0000 - val_loss: 42.9321 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9926\n",
      "Epoch 65: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 47.7840 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 66: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 38.2647 - val_accuracy: 0.0857\n",
      "Epoch 67/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9926\n",
      "Epoch 67: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0101 - accuracy: 0.9926 - val_loss: 49.6267 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 6.3945e-04 - accuracy: 1.0000\n",
      "Epoch 68: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 6.3945e-04 - accuracy: 1.0000 - val_loss: 46.9351 - val_accuracy: 0.0286\n",
      "Epoch 69/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 69: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 49.7089 - val_accuracy: 0.0286\n",
      "Epoch 70/70\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.6316e-04 - accuracy: 1.0000\n",
      "Epoch 70: val_loss did not improve from 11.38504\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 1.6316e-04 - accuracy: 1.0000 - val_loss: 48.9277 - val_accuracy: 0.0286\n"
     ]
    }
   ],
   "source": [
    "model_cnn.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_cnn = model_cnn.fit(\n",
    "    X_train_cnn, y_train_cnn,\n",
    "    epochs = 70,\n",
    "    batch_size = 32, # données transmises pour une session\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 68ms/step - loss: 12.5316 - accuracy: 0.4651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.531560897827148, 0.4651162922382355]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.evaluate(X_test_cnn, y_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.10227513e-09, 1.00000000e+00, 1.32505465e-12, 4.61441547e-17],\n",
       "       [9.99992013e-01, 1.13003495e-07, 7.83554515e-06, 3.15865059e-25],\n",
       "       [2.73185894e-02, 2.07257050e-04, 9.72474158e-01, 1.48067355e-25],\n",
       "       [5.79412937e-01, 4.20587033e-01, 1.77708015e-09, 1.94915438e-21],\n",
       "       [2.91187898e-04, 9.99708831e-01, 1.63423081e-21, 6.81038953e-35],\n",
       "       [9.99757588e-01, 1.99009912e-04, 4.33617461e-05, 1.50830493e-36],\n",
       "       [9.28058743e-01, 7.10723251e-02, 8.68952600e-04, 2.49300099e-23],\n",
       "       [9.99992967e-01, 7.02123907e-06, 7.17429362e-17, 2.30603052e-27],\n",
       "       [2.40731822e-07, 9.99999762e-01, 2.84012028e-14, 9.87735591e-30],\n",
       "       [6.93466246e-01, 3.06484908e-01, 4.88719124e-05, 9.27294457e-25],\n",
       "       [9.99943018e-01, 5.68023970e-05, 1.39527458e-07, 2.60141890e-26],\n",
       "       [1.00000000e+00, 1.87313179e-10, 1.28742208e-11, 0.00000000e+00],\n",
       "       [9.97323632e-01, 2.46249674e-05, 2.65174056e-03, 7.19965145e-20],\n",
       "       [1.60385177e-01, 8.39614868e-01, 4.60369448e-16, 1.41056927e-32],\n",
       "       [9.80812311e-01, 1.91876832e-02, 1.93958478e-12, 6.31231965e-30],\n",
       "       [3.08906565e-05, 9.99969125e-01, 8.45803326e-14, 1.65816316e-22],\n",
       "       [2.08745059e-02, 9.76327956e-01, 2.79754773e-03, 3.63924282e-20],\n",
       "       [2.01055016e-07, 9.35363472e-01, 6.46363497e-02, 3.13672644e-21],\n",
       "       [8.92987192e-01, 8.46636226e-07, 1.07011959e-01, 4.76110996e-38],\n",
       "       [1.00000000e+00, 3.34670074e-12, 1.09451585e-13, 0.00000000e+00],\n",
       "       [2.50646612e-04, 9.99749362e-01, 1.81133129e-11, 2.13824992e-23],\n",
       "       [9.90390658e-01, 9.56179015e-03, 4.75282068e-05, 1.68880797e-25],\n",
       "       [6.06206231e-06, 3.71640788e-14, 9.99993920e-01, 4.84658804e-38],\n",
       "       [2.22738716e-04, 9.99777257e-01, 1.09775911e-09, 4.13548753e-12],\n",
       "       [2.22350245e-05, 9.99977708e-01, 1.12667523e-11, 3.17505070e-15],\n",
       "       [2.46946570e-02, 9.75226283e-01, 7.90739723e-05, 9.20605105e-20],\n",
       "       [2.01567356e-02, 1.83210149e-01, 7.96633124e-01, 2.64921070e-21],\n",
       "       [4.24502231e-02, 8.94990325e-01, 6.25594854e-02, 2.26488584e-15],\n",
       "       [9.99998093e-01, 9.57742941e-07, 9.46844864e-07, 2.86501113e-30],\n",
       "       [1.17713068e-06, 9.99998808e-01, 1.15438997e-16, 0.00000000e+00],\n",
       "       [4.96653030e-09, 1.00000000e+00, 3.70408773e-11, 8.14856091e-26],\n",
       "       [2.89495021e-01, 6.83645964e-01, 2.68590618e-02, 2.04418096e-26],\n",
       "       [8.08408856e-01, 1.91591114e-01, 5.22837640e-09, 5.09218373e-13],\n",
       "       [9.56761897e-01, 4.32380699e-02, 1.19518417e-09, 1.07484674e-30],\n",
       "       [1.00000000e+00, 4.16064623e-08, 1.01842692e-11, 6.45815347e-33],\n",
       "       [9.97397184e-01, 2.60242936e-03, 3.56353638e-07, 1.40928309e-16],\n",
       "       [3.66196645e-07, 9.99999642e-01, 1.43902860e-21, 3.56555776e-29],\n",
       "       [1.03757508e-01, 8.96242559e-01, 8.07280544e-12, 3.19083393e-27],\n",
       "       [9.99999523e-01, 5.33818934e-07, 3.59939617e-13, 5.10642909e-30],\n",
       "       [9.83598828e-01, 1.64011568e-02, 1.45002570e-08, 4.50060115e-15],\n",
       "       [8.02247523e-05, 9.99919772e-01, 7.94791344e-09, 8.30145311e-18],\n",
       "       [9.99917269e-01, 8.27812546e-05, 5.93749633e-11, 1.41363458e-26],\n",
       "       [9.99995947e-01, 4.04036200e-06, 1.36779366e-09, 9.32823387e-33]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cnn = model_cnn.predict(X_test_cnn)\n",
    "pred_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:  [1 0 2 0 1 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1 0 2 1 1 1 2 1 0 1 1 1 0 0 0 0 1\n",
      " 1 0 0 1 0 0]\n",
      "True labels:       [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "y_pred_cnn = np.argmax(pred_cnn, axis=1)\n",
    "print(\"Predicted labels: \", y_pred_cnn)\n",
    "print(\"True labels:      \", y_test_cnn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy: $20/43$ ($46.51 \\%$)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
