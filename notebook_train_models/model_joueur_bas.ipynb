{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle de réseau de neurones sur le dataset du Joueur bas - Henri, Minh, Maxime\n",
    "- Coup droit\n",
    "- Déplacement\n",
    "- Revers\n",
    "- Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from smart.video import Video, Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "path_dataset = 'img/JBas'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau de neurones classique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prises des frames et des vidéos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_videos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "all_paths = []\n",
    "for dirpath, dirnames, _ in os.walk(path_dataset):\n",
    "    for dir_type in dirnames:\n",
    "        \n",
    "        path_fol = os.path.join(dirpath, dir_type)\n",
    "        for file in os.listdir(path_fol):\n",
    "            path_fol_img = os.path.join(path_fol, file)\n",
    "            if os.path.isdir(path_fol_img) and file == 'images':\n",
    "                frames = []\n",
    "                for file_img in os.listdir(path_fol_img):\n",
    "                    path_img = os.path.join(path_fol_img, file_img)\n",
    "                    img_obj = Image.load_image(cv2.IMREAD_GRAYSCALE, path_img)\n",
    "                    img = img_obj.img\n",
    "                    frames.append(img)\t\n",
    "                if (len(frames) == 15):\n",
    "                    output_res = path_img.split('\\\\')[1]\n",
    "                    all_paths.append(path_fol_img)\n",
    "                    vid = Video.read_video_from_frames(frames)\n",
    "                    list_videos.append(vid)\n",
    "                    y.append(output_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<smart.video.Video.Video at 0x17ea0b02eb0>,\n",
       " <smart.video.Video.Video at 0x17e9d42d970>,\n",
       " <smart.video.Video.Video at 0x17ea0affdf0>,\n",
       " <smart.video.Video.Video at 0x17ea0b10ac0>,\n",
       " <smart.video.Video.Video at 0x17ea093b0a0>,\n",
       " <smart.video.Video.Video at 0x17ea0b10460>,\n",
       " <smart.video.Video.Video at 0x17ea0b1df40>,\n",
       " <smart.video.Video.Video at 0x17ea0b1df70>,\n",
       " <smart.video.Video.Video at 0x17e9ee14730>,\n",
       " <smart.video.Video.Video at 0x17e9ee4f640>,\n",
       " <smart.video.Video.Video at 0x17ea0b1db20>,\n",
       " <smart.video.Video.Video at 0x17e9ed50610>,\n",
       " <smart.video.Video.Video at 0x17e9ed50190>,\n",
       " <smart.video.Video.Video at 0x17e9ed508b0>,\n",
       " <smart.video.Video.Video at 0x17e9ee149a0>,\n",
       " <smart.video.Video.Video at 0x17ea0b25ac0>,\n",
       " <smart.video.Video.Video at 0x17ea0b25a60>,\n",
       " <smart.video.Video.Video at 0x17ea0b25b50>,\n",
       " <smart.video.Video.Video at 0x17ea0b25bb0>,\n",
       " <smart.video.Video.Video at 0x17ea0b25c10>,\n",
       " <smart.video.Video.Video at 0x17ea0b25c70>,\n",
       " <smart.video.Video.Video at 0x17ea0b25d00>,\n",
       " <smart.video.Video.Video at 0x17ea0b25d60>,\n",
       " <smart.video.Video.Video at 0x17ea0b25d90>,\n",
       " <smart.video.Video.Video at 0x17ea0b25df0>,\n",
       " <smart.video.Video.Video at 0x17ea0b25e50>,\n",
       " <smart.video.Video.Video at 0x17ea0b25eb0>,\n",
       " <smart.video.Video.Video at 0x17ea0b25f10>,\n",
       " <smart.video.Video.Video at 0x17e9ee18ac0>,\n",
       " <smart.video.Video.Video at 0x17ea0b25fa0>,\n",
       " <smart.video.Video.Video at 0x17e9ed50580>,\n",
       " <smart.video.Video.Video at 0x17ea0b25a90>,\n",
       " <smart.video.Video.Video at 0x17e9ee093a0>,\n",
       " <smart.video.Video.Video at 0x17e9ee18970>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a0d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a130>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a190>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a1f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a250>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a2b0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a310>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a370>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a3d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a430>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a490>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a4f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a550>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a5b0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a610>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a670>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a6d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a730>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a790>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a7f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a850>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a8b0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a910>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a970>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a9d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2aa30>,\n",
       " <smart.video.Video.Video at 0x17ea0b2aa90>,\n",
       " <smart.video.Video.Video at 0x17ea0b2aaf0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2ab50>,\n",
       " <smart.video.Video.Video at 0x17ea0b2abb0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2ac10>,\n",
       " <smart.video.Video.Video at 0x17ea0b2ac70>,\n",
       " <smart.video.Video.Video at 0x17ea0b2acd0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2ad30>,\n",
       " <smart.video.Video.Video at 0x17ea0b2ad90>,\n",
       " <smart.video.Video.Video at 0x17ea0b2adf0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2ae50>,\n",
       " <smart.video.Video.Video at 0x17ea0b2aeb0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2af10>,\n",
       " <smart.video.Video.Video at 0x17ea0b2afd0>,\n",
       " <smart.video.Video.Video at 0x17e9d432c10>,\n",
       " <smart.video.Video.Video at 0x17ea0b2a040>,\n",
       " <smart.video.Video.Video at 0x17ea0b380d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38130>,\n",
       " <smart.video.Video.Video at 0x17ea0b38190>,\n",
       " <smart.video.Video.Video at 0x17ea0b381f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38250>,\n",
       " <smart.video.Video.Video at 0x17ea0b382b0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38310>,\n",
       " <smart.video.Video.Video at 0x17ea0b38370>,\n",
       " <smart.video.Video.Video at 0x17ea0b383d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38430>,\n",
       " <smart.video.Video.Video at 0x17ea0b38490>,\n",
       " <smart.video.Video.Video at 0x17ea0b384f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38550>,\n",
       " <smart.video.Video.Video at 0x17ea0b385b0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38610>,\n",
       " <smart.video.Video.Video at 0x17ea0b38670>,\n",
       " <smart.video.Video.Video at 0x17ea0b386d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38730>,\n",
       " <smart.video.Video.Video at 0x17ea0b38790>,\n",
       " <smart.video.Video.Video at 0x17ea0b387f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38850>,\n",
       " <smart.video.Video.Video at 0x17ea0b388b0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38910>,\n",
       " <smart.video.Video.Video at 0x17ea0b38970>,\n",
       " <smart.video.Video.Video at 0x17ea0b389d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38a30>,\n",
       " <smart.video.Video.Video at 0x17ea0b38a90>,\n",
       " <smart.video.Video.Video at 0x17ea0b38af0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38b50>,\n",
       " <smart.video.Video.Video at 0x17ea0b38bb0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38c10>,\n",
       " <smart.video.Video.Video at 0x17ea0b38c70>,\n",
       " <smart.video.Video.Video at 0x17ea0b38cd0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38d30>,\n",
       " <smart.video.Video.Video at 0x17ea0b38d90>,\n",
       " <smart.video.Video.Video at 0x17ea0b38df0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38e50>,\n",
       " <smart.video.Video.Video at 0x17ea0b38eb0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38f10>,\n",
       " <smart.video.Video.Video at 0x17ea0b38fa0>,\n",
       " <smart.video.Video.Video at 0x17ea0b2af70>,\n",
       " <smart.video.Video.Video at 0x17ea0b38040>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a0d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a130>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a190>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a1f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a250>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a2b0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a310>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a370>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a3d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a430>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a490>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a4f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a550>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a5b0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a610>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a670>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a6d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a730>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a790>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a7f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b38fd0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a850>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a8e0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a940>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a9a0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3aa00>,\n",
       " <smart.video.Video.Video at 0x17ea0b3aaf0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3a070>,\n",
       " <smart.video.Video.Video at 0x17ea0b3abb0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ac10>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ab80>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ac70>,\n",
       " <smart.video.Video.Video at 0x17ea0b3acd0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ac40>,\n",
       " <smart.video.Video.Video at 0x17ea0b3adc0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ad60>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ae80>,\n",
       " <smart.video.Video.Video at 0x17ea0b3aeb0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ae20>,\n",
       " <smart.video.Video.Video at 0x17ea0b3af40>,\n",
       " <smart.video.Video.Video at 0x17ea0b3af70>,\n",
       " <smart.video.Video.Video at 0x17ea0ac2af0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e0d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e070>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e160>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e220>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e1f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e310>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e280>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e340>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e3a0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e400>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e460>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e4c0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e520>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e610>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e5b0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e640>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e6a0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e790>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e7f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e850>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e7c0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e880>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e8e0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e940>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ea00>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e9a0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3eaf0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e9d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ea90>,\n",
       " <smart.video.Video.Video at 0x17ea0b3eac0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ebb0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ec10>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ec70>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ecd0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ed30>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ed90>,\n",
       " <smart.video.Video.Video at 0x17ea0b3edf0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ee50>,\n",
       " <smart.video.Video.Video at 0x17ea0b3eeb0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3efa0>,\n",
       " <smart.video.Video.Video at 0x17ea0b3ef70>,\n",
       " <smart.video.Video.Video at 0x17ea0b3e0a0>,\n",
       " <smart.video.Video.Video at 0x17ea0b430d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b43130>,\n",
       " <smart.video.Video.Video at 0x17ea0b43190>,\n",
       " <smart.video.Video.Video at 0x17ea0b431f0>,\n",
       " <smart.video.Video.Video at 0x17ea0b43250>,\n",
       " <smart.video.Video.Video at 0x17ea0b432b0>,\n",
       " <smart.video.Video.Video at 0x17ea0b43310>,\n",
       " <smart.video.Video.Video at 0x17ea0b43370>,\n",
       " <smart.video.Video.Video at 0x17ea0b433d0>,\n",
       " <smart.video.Video.Video at 0x17ea0b43430>,\n",
       " <smart.video.Video.Video at 0x17ea0b43490>,\n",
       " <smart.video.Video.Video at 0x17ea0b434f0>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'coup droit',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'deplacement',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'revers',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service',\n",
       " 'service']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output sans label encoder\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer output y en one hot vector\n",
    "- 0: coup droit\n",
    "- 1: déplacement\n",
    "- 2: revers\n",
    "- 3: service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_y = np.unique(y)\n",
    "output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37500"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résolution des images\n",
    "input_shape_model = list_videos[0].frames.shape[0] * list_videos[0].frames.shape[1] * list_videos[0].frames.shape[2]\n",
    "input_shape_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(list_videos) * 0.8)\n",
    "test_size = len(list_videos) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 171, 43, 43)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split video train, test\n",
    "random.seed(42)\n",
    "vids_train = random.sample(list_videos, k = train_size)\n",
    "vids_test = [vid for vid in list_videos if vid not in vids_train]\n",
    "y_train = [y[i] for i in range(len(y)) if list_videos[i] in vids_train]\n",
    "y_test = [y[i] for i in range(len(y)) if list_videos[i] in vids_test]\n",
    "paths_test = [all_paths[i] for i in range(len(all_paths)) if list_videos[i] in vids_test]\n",
    "len(vids_train), len(y_train), len(vids_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img/JBas\\\\coup droit\\\\1980-2563441\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\1980-2563523\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\42698-4288095\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\a36r805\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\Alcaraz_Sinner270\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\AS_13416\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\AS_22373\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\AS_30502\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\AS_37288\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\AS_40159\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\car0001-0342253\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\car5493-5847185\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\na0201977\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\uopc1041\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\uopc1683\\\\images',\n",
       " 'img/JBas\\\\coup droit\\\\uopc339\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\a36r1216\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\a36r1713\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\a36r172\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\a36r257\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\a36r339\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\AS_13292\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\AS_40133\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\car5936-6390437\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\ivjs985\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\na0201125\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\na0201446\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\na0201578\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\na0201831\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\uopc1067\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\uopc227\\\\images',\n",
       " 'img/JBas\\\\deplacement\\\\uopc304\\\\images',\n",
       " 'img/JBas\\\\revers\\\\a36r1276\\\\images',\n",
       " 'img/JBas\\\\revers\\\\AS_24472\\\\images',\n",
       " 'img/JBas\\\\revers\\\\AS_35566\\\\images',\n",
       " 'img/JBas\\\\revers\\\\car2491-2852287\\\\images',\n",
       " 'img/JBas\\\\revers\\\\clip_usopen896\\\\images',\n",
       " 'img/JBas\\\\revers\\\\na02011281\\\\images',\n",
       " 'img/JBas\\\\revers\\\\na02011743\\\\images',\n",
       " 'img/JBas\\\\service\\\\AS_34155\\\\images',\n",
       " 'img/JBas\\\\service\\\\car0001-0342180\\\\images',\n",
       " 'img/JBas\\\\service\\\\car2491-2852108\\\\images',\n",
       " 'img/JBas\\\\service\\\\car5493-5847116\\\\images']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_train, dtype=int)\n",
    "y_test = np.array(y_test, dtype=int)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split input X en train, test set\n",
    "X_train = np.zeros((train_size, 50*50*15), dtype=int)\n",
    "for i, vid in enumerate(vids_train):\n",
    "    seq_img = vid.frames.flatten()\n",
    "    X_train[i] = seq_img\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.zeros((test_size, 50*50*15), dtype=int)\n",
    "for i, vid in enumerate(vids_test):\n",
    "    seq_img = vid.frames.flatten()\n",
    "    X_test[i] = seq_img\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle de réseau de neurones avec classification multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 32)                1200032   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,210,980\n",
      "Trainable params: 1,210,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1234) # for consistent results\n",
    "model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape = input_shape_model), # 50*50 * 15 = 37500\n",
    "        # Dense(units=16, activation=\"relu\"),\n",
    "        Dense(units=32, activation=\"relu\"),\n",
    "        Dense(units=64, activation=\"sigmoid\"),\n",
    "        Dense(units=128, activation=\"relu\"),\n",
    "        Dense(units=len(output_y), activation=\"softmax\"),\n",
    "    ]\n",
    ")          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'checkpoints/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/5 [=====>........................] - ETA: 1s - loss: 1.3837 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 1: val_loss improved from inf to 1.68214, saving model to checkpoints\\Weights-001--1.68214.hdf5\n",
      "5/5 [==============================] - 1s 69ms/step - loss: 1.3761 - sparse_categorical_accuracy: 0.3676 - val_loss: 1.6821 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3026 - sparse_categorical_accuracy: 0.4375\n",
      "Epoch 2: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.2711 - sparse_categorical_accuracy: 0.3676 - val_loss: 1.8609 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2605 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 3: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1988 - sparse_categorical_accuracy: 0.3897 - val_loss: 1.9903 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2110 - sparse_categorical_accuracy: 0.5312\n",
      "Epoch 4: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1458 - sparse_categorical_accuracy: 0.6544 - val_loss: 2.0692 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1328 - sparse_categorical_accuracy: 0.7188\n",
      "Epoch 5: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0980 - sparse_categorical_accuracy: 0.7279 - val_loss: 2.1709 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0696 - sparse_categorical_accuracy: 0.6875\n",
      "Epoch 6: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0608 - sparse_categorical_accuracy: 0.6985 - val_loss: 2.2612 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0319 - sparse_categorical_accuracy: 0.7500\n",
      "Epoch 7: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0226 - sparse_categorical_accuracy: 0.7500 - val_loss: 2.3169 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.0009 - sparse_categorical_accuracy: 0.7422\n",
      "Epoch 8: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.9887 - sparse_categorical_accuracy: 0.7574 - val_loss: 2.3611 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.9572 - sparse_categorical_accuracy: 0.6641\n",
      "Epoch 9: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.9628 - sparse_categorical_accuracy: 0.6544 - val_loss: 2.4309 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.9268 - sparse_categorical_accuracy: 0.7426\n",
      "Epoch 10: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.9268 - sparse_categorical_accuracy: 0.7426 - val_loss: 2.4422 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.8927 - sparse_categorical_accuracy: 0.7656\n",
      "Epoch 11: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.8935 - sparse_categorical_accuracy: 0.7647 - val_loss: 2.4444 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8587 - sparse_categorical_accuracy: 0.7574\n",
      "Epoch 12: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.8587 - sparse_categorical_accuracy: 0.7574 - val_loss: 2.4478 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8244 - sparse_categorical_accuracy: 0.7574\n",
      "Epoch 13: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.8244 - sparse_categorical_accuracy: 0.7574 - val_loss: 2.4521 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.7953 - sparse_categorical_accuracy: 0.7868\n",
      "Epoch 14: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.7953 - sparse_categorical_accuracy: 0.7868 - val_loss: 2.4874 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.7606 - sparse_categorical_accuracy: 0.7891\n",
      "Epoch 15: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.7578 - sparse_categorical_accuracy: 0.7868 - val_loss: 2.5445 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.7798 - sparse_categorical_accuracy: 0.8125\n",
      "Epoch 16: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.7267 - sparse_categorical_accuracy: 0.8235 - val_loss: 2.5272 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6853 - sparse_categorical_accuracy: 0.8676\n",
      "Epoch 17: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.6853 - sparse_categorical_accuracy: 0.8676 - val_loss: 2.5110 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6591 - sparse_categorical_accuracy: 0.8824\n",
      "Epoch 18: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6591 - sparse_categorical_accuracy: 0.8824 - val_loss: 2.5111 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6215 - sparse_categorical_accuracy: 0.9338\n",
      "Epoch 19: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.6215 - sparse_categorical_accuracy: 0.9338 - val_loss: 2.5799 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5956 - sparse_categorical_accuracy: 0.9265\n",
      "Epoch 20: val_loss did not improve from 1.68214\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5956 - sparse_categorical_accuracy: 0.9265 - val_loss: 2.6353 - val_sparse_categorical_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 20,\n",
    "    batch_size = 32, # données transmises pour une session\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 1.2803 - sparse_categorical_accuracy: 0.3488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2802684307098389, 0.3488371968269348]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.28639475, 0.51444954, 0.17073978, 0.02841597],\n",
       "       [0.33815065, 0.3913074 , 0.23877911, 0.03176285],\n",
       "       [0.3544661 , 0.45454392, 0.16265403, 0.02833588],\n",
       "       [0.3341438 , 0.45314983, 0.18287466, 0.02983169],\n",
       "       [0.32503226, 0.4786257 , 0.16444069, 0.03190125],\n",
       "       [0.37055272, 0.40622208, 0.19302982, 0.03019539],\n",
       "       [0.42032325, 0.32195306, 0.22464113, 0.03308259],\n",
       "       [0.47009557, 0.30990306, 0.18372357, 0.03627783],\n",
       "       [0.2990541 , 0.5035109 , 0.16715892, 0.03027602],\n",
       "       [0.37917268, 0.42190105, 0.16863847, 0.03028771],\n",
       "       [0.4184212 , 0.3466131 , 0.20369585, 0.03126984],\n",
       "       [0.4739001 , 0.31713077, 0.17837945, 0.0305897 ],\n",
       "       [0.34033954, 0.45189917, 0.17891619, 0.02884514],\n",
       "       [0.4034711 , 0.36759067, 0.1962039 , 0.03273435],\n",
       "       [0.36400867, 0.43748397, 0.16947964, 0.02902766],\n",
       "       [0.4165887 , 0.3620459 , 0.1902865 , 0.03107897],\n",
       "       [0.34564933, 0.42356148, 0.20090973, 0.02987945],\n",
       "       [0.33287156, 0.47263396, 0.16612187, 0.02837267],\n",
       "       [0.33962467, 0.44202146, 0.1886508 , 0.02970308],\n",
       "       [0.36510473, 0.41411442, 0.19025186, 0.03052897],\n",
       "       [0.3638543 , 0.40353355, 0.20264488, 0.02996724],\n",
       "       [0.42342815, 0.3574163 , 0.1900612 , 0.02909439],\n",
       "       [0.32716447, 0.31533375, 0.32243893, 0.03506291],\n",
       "       [0.39611152, 0.3156618 , 0.22802229, 0.06020441],\n",
       "       [0.2793454 , 0.55049944, 0.14557192, 0.02458329],\n",
       "       [0.3728455 , 0.35616833, 0.23639704, 0.03458911],\n",
       "       [0.4340353 , 0.33985218, 0.19499099, 0.03112152],\n",
       "       [0.42810142, 0.33416146, 0.20521167, 0.03252542],\n",
       "       [0.45538288, 0.34041125, 0.17412686, 0.03007907],\n",
       "       [0.40697548, 0.3662315 , 0.19578911, 0.0310038 ],\n",
       "       [0.3256113 , 0.44816673, 0.19698134, 0.02924063],\n",
       "       [0.35906577, 0.38163447, 0.22644591, 0.03285382],\n",
       "       [0.42108923, 0.28186807, 0.25580806, 0.04123466],\n",
       "       [0.3777663 , 0.33805907, 0.24895887, 0.03521573],\n",
       "       [0.3979853 , 0.39819717, 0.17271231, 0.03110524],\n",
       "       [0.4263907 , 0.30742785, 0.22965   , 0.03653144],\n",
       "       [0.4754294 , 0.28812543, 0.20397367, 0.03247153],\n",
       "       [0.4699178 , 0.29575405, 0.19725077, 0.03707743],\n",
       "       [0.3391645 , 0.45924482, 0.17068617, 0.03090461],\n",
       "       [0.43704772, 0.27613327, 0.24304675, 0.04377229],\n",
       "       [0.40532535, 0.36549634, 0.19449618, 0.03468214],\n",
       "       [0.37654886, 0.40132624, 0.18886055, 0.03326438],\n",
       "       [0.4843834 , 0.30728173, 0.17813659, 0.03019834]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:  [1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 0]\n",
      "True labels:       [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(pred, axis=1)\n",
    "print(\"Predicted labels: \", y_pred)\n",
    "print(\"True labels:      \", y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy: $17 / 43$ ($39.53 \\%$)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseaux de neurones convolutifs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prises des frames et des vidéos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_videos_cnn = []\n",
    "y_cnn = []\n",
    "for dirpath, dirnames, _ in os.walk(path_dataset):\n",
    "    for dir_type in dirnames:\n",
    "        \n",
    "        path_fol = os.path.join(dirpath, dir_type)\n",
    "        for file in os.listdir(path_fol):\n",
    "            path_fol_img = os.path.join(path_fol, file)\n",
    "            if os.path.isdir(path_fol_img) and file == 'images':\n",
    "                frames = []\n",
    "                for file_img in os.listdir(path_fol_img):\n",
    "                    path_img = os.path.join(path_fol_img, file_img)\n",
    "                    img_obj = Image.load_image(cv2.IMREAD_GRAYSCALE, path_img)\n",
    "                    img = img_obj.img\n",
    "                    frames.append(img)\t\n",
    "                if (len(frames) == 15):\n",
    "                    output_res = path_img.split('\\\\')[1]\n",
    "                    vid = Video.read_video_from_frames(frames)\n",
    "                    list_videos_cnn.append(vid)\n",
    "                    y_cnn.append(output_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_videos_cnn[0].frames.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer output y en one hot vector\n",
    "- 0: coup droit\n",
    "- 1: déplacement\n",
    "- 2: revers\n",
    "- 3: service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cnn = encoder.fit_transform(y_cnn)\n",
    "y_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_y = np.unique(y_cnn)\n",
    "output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_videos_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(list_videos_cnn) * 0.8)\n",
    "test_size = len(list_videos_cnn) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 171, 43, 43)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split video train, test\n",
    "random.seed(42)\n",
    "vids_train_cnn = random.sample(list_videos_cnn, k = train_size)\n",
    "vids_test_cnn = [vid for vid in list_videos_cnn if vid not in vids_train_cnn]\n",
    "y_train_cnn = [y_cnn[i] for i in range(len(y_cnn)) if list_videos_cnn[i] in vids_train_cnn]\n",
    "y_test_cnn = [y_cnn[i] for i in range(len(y_cnn)) if list_videos_cnn[i] in vids_test_cnn]\n",
    "len(vids_train_cnn), len(y_train_cnn), len(vids_test_cnn), len(y_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cnn = np.array(y_train_cnn, dtype=int)\n",
    "y_test_cnn = np.array(y_test_cnn, dtype=int)\n",
    "y_train_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 50, 750, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split input X en train, test set\n",
    "X_train_cnn = np.zeros((train_size, 50, 15*50, 1), dtype=int)\n",
    "for i, vid in enumerate(vids_train_cnn):\n",
    "    for j, frame in enumerate(vid.frames):\n",
    "        X_train_cnn[i, :, 50*j:50*(j+1), :] = frame.reshape(50, 50, 1)\n",
    "X_train_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 50, 750, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cnn = np.zeros((test_size, 50, 15*50, 1), dtype=int)\n",
    "for i, vid in enumerate(vids_test_cnn):\n",
    "    for j, frame in enumerate(vid.frames):\n",
    "        X_test_cnn[i, :, 50*j:50*(j+1), :] = frame.reshape(50, 50, 1)\n",
    "X_test_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 750, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape_cnn = X_train_cnn.shape[1:]\n",
    "input_shape_cnn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle de réseau de neurones convolutifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 748, 16)       160       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 748, 16)      64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 374, 16)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 374, 16)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 22, 372, 32)       4640      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 22, 372, 32)      128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 11, 186, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 11, 186, 32)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 184, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 9, 184, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 92, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 92, 64)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23552)             0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               3014784   \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,039,044\n",
      "Trainable params: 3,038,820\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape = input_shape_cnn), # 50, 15*50, 3\n",
    "        Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(units=128, activation=\"relu\"),\n",
    "        Dense(units=len(output_y), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'checkpoints/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.4379 - sparse_categorical_accuracy: 0.2500\n",
      "Epoch 1: val_loss improved from inf to 67.27535, saving model to checkpoints\\Weights-001--67.27535.hdf5\n",
      "5/5 [==============================] - 4s 662ms/step - loss: 2.4379 - sparse_categorical_accuracy: 0.2500 - val_loss: 67.2754 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.3056 - sparse_categorical_accuracy: 0.4632\n",
      "Epoch 2: val_loss improved from 67.27535 to 62.25179, saving model to checkpoints\\Weights-002--62.25179.hdf5\n",
      "5/5 [==============================] - 3s 609ms/step - loss: 1.3056 - sparse_categorical_accuracy: 0.4632 - val_loss: 62.2518 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8877 - sparse_categorical_accuracy: 0.5956\n",
      "Epoch 3: val_loss improved from 62.25179 to 56.84739, saving model to checkpoints\\Weights-003--56.84739.hdf5\n",
      "5/5 [==============================] - 3s 634ms/step - loss: 0.8877 - sparse_categorical_accuracy: 0.5956 - val_loss: 56.8474 - val_sparse_categorical_accuracy: 0.2286\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.7020 - sparse_categorical_accuracy: 0.7206\n",
      "Epoch 4: val_loss improved from 56.84739 to 53.10709, saving model to checkpoints\\Weights-004--53.10709.hdf5\n",
      "5/5 [==============================] - 3s 599ms/step - loss: 0.7020 - sparse_categorical_accuracy: 0.7206 - val_loss: 53.1071 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4493 - sparse_categorical_accuracy: 0.8382\n",
      "Epoch 5: val_loss improved from 53.10709 to 49.07081, saving model to checkpoints\\Weights-005--49.07081.hdf5\n",
      "5/5 [==============================] - 3s 571ms/step - loss: 0.4493 - sparse_categorical_accuracy: 0.8382 - val_loss: 49.0708 - val_sparse_categorical_accuracy: 0.1714\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4720 - sparse_categorical_accuracy: 0.8015\n",
      "Epoch 6: val_loss improved from 49.07081 to 46.37592, saving model to checkpoints\\Weights-006--46.37592.hdf5\n",
      "5/5 [==============================] - 3s 536ms/step - loss: 0.4720 - sparse_categorical_accuracy: 0.8015 - val_loss: 46.3759 - val_sparse_categorical_accuracy: 0.1143\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4562 - sparse_categorical_accuracy: 0.8162\n",
      "Epoch 7: val_loss improved from 46.37592 to 43.28378, saving model to checkpoints\\Weights-007--43.28378.hdf5\n",
      "5/5 [==============================] - 2s 446ms/step - loss: 0.4562 - sparse_categorical_accuracy: 0.8162 - val_loss: 43.2838 - val_sparse_categorical_accuracy: 0.1429\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2993 - sparse_categorical_accuracy: 0.8603\n",
      "Epoch 8: val_loss improved from 43.28378 to 41.08792, saving model to checkpoints\\Weights-008--41.08792.hdf5\n",
      "5/5 [==============================] - 2s 476ms/step - loss: 0.2993 - sparse_categorical_accuracy: 0.8603 - val_loss: 41.0879 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2674 - sparse_categorical_accuracy: 0.8897\n",
      "Epoch 9: val_loss improved from 41.08792 to 39.11787, saving model to checkpoints\\Weights-009--39.11787.hdf5\n",
      "5/5 [==============================] - 3s 503ms/step - loss: 0.2674 - sparse_categorical_accuracy: 0.8897 - val_loss: 39.1179 - val_sparse_categorical_accuracy: 0.0571\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3434 - sparse_categorical_accuracy: 0.8676\n",
      "Epoch 10: val_loss improved from 39.11787 to 36.99070, saving model to checkpoints\\Weights-010--36.99070.hdf5\n",
      "5/5 [==============================] - 2s 434ms/step - loss: 0.3434 - sparse_categorical_accuracy: 0.8676 - val_loss: 36.9907 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3218 - sparse_categorical_accuracy: 0.8529\n",
      "Epoch 11: val_loss improved from 36.99070 to 35.54775, saving model to checkpoints\\Weights-011--35.54775.hdf5\n",
      "5/5 [==============================] - 2s 416ms/step - loss: 0.3218 - sparse_categorical_accuracy: 0.8529 - val_loss: 35.5477 - val_sparse_categorical_accuracy: 0.0571\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3353 - sparse_categorical_accuracy: 0.8603\n",
      "Epoch 12: val_loss improved from 35.54775 to 33.53698, saving model to checkpoints\\Weights-012--33.53698.hdf5\n",
      "5/5 [==============================] - 3s 499ms/step - loss: 0.3353 - sparse_categorical_accuracy: 0.8603 - val_loss: 33.5370 - val_sparse_categorical_accuracy: 0.1143\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1941 - sparse_categorical_accuracy: 0.9044\n",
      "Epoch 13: val_loss improved from 33.53698 to 32.95123, saving model to checkpoints\\Weights-013--32.95123.hdf5\n",
      "5/5 [==============================] - 3s 539ms/step - loss: 0.1941 - sparse_categorical_accuracy: 0.9044 - val_loss: 32.9512 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2498 - sparse_categorical_accuracy: 0.8971\n",
      "Epoch 14: val_loss improved from 32.95123 to 31.94040, saving model to checkpoints\\Weights-014--31.94040.hdf5\n",
      "5/5 [==============================] - 3s 523ms/step - loss: 0.2498 - sparse_categorical_accuracy: 0.8971 - val_loss: 31.9404 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2424 - sparse_categorical_accuracy: 0.8676\n",
      "Epoch 15: val_loss improved from 31.94040 to 30.72942, saving model to checkpoints\\Weights-015--30.72942.hdf5\n",
      "5/5 [==============================] - 3s 507ms/step - loss: 0.2424 - sparse_categorical_accuracy: 0.8676 - val_loss: 30.7294 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1242 - sparse_categorical_accuracy: 0.9779\n",
      "Epoch 16: val_loss improved from 30.72942 to 30.03237, saving model to checkpoints\\Weights-016--30.03237.hdf5\n",
      "5/5 [==============================] - 3s 499ms/step - loss: 0.1242 - sparse_categorical_accuracy: 0.9779 - val_loss: 30.0324 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1179 - sparse_categorical_accuracy: 0.9632\n",
      "Epoch 17: val_loss improved from 30.03237 to 29.29508, saving model to checkpoints\\Weights-017--29.29508.hdf5\n",
      "5/5 [==============================] - 3s 591ms/step - loss: 0.1179 - sparse_categorical_accuracy: 0.9632 - val_loss: 29.2951 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0923 - sparse_categorical_accuracy: 0.9706\n",
      "Epoch 18: val_loss improved from 29.29508 to 28.28434, saving model to checkpoints\\Weights-018--28.28434.hdf5\n",
      "5/5 [==============================] - 3s 496ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9706 - val_loss: 28.2843 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0601 - sparse_categorical_accuracy: 0.9853\n",
      "Epoch 19: val_loss improved from 28.28434 to 28.19489, saving model to checkpoints\\Weights-019--28.19489.hdf5\n",
      "5/5 [==============================] - 3s 464ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9853 - val_loss: 28.1949 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0646 - sparse_categorical_accuracy: 0.9853\n",
      "Epoch 20: val_loss improved from 28.19489 to 27.64005, saving model to checkpoints\\Weights-020--27.64005.hdf5\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.0646 - sparse_categorical_accuracy: 0.9853 - val_loss: 27.6400 - val_sparse_categorical_accuracy: 0.0857\n"
     ]
    }
   ],
   "source": [
    "model_cnn.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "history_cnn = model_cnn.fit(\n",
    "    X_train_cnn, y_train_cnn,\n",
    "    epochs = 20,\n",
    "    batch_size = 32, # données transmises pour une session\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 81ms/step - loss: 4.7984 - sparse_categorical_accuracy: 0.3256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.798425197601318, 0.3255814015865326]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.evaluate(X_test_cnn, y_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.98157134e-03, 9.93046939e-01, 1.97145552e-03, 1.31618317e-19],\n",
       "       [3.64651293e-01, 3.11381947e-02, 6.04210496e-01, 2.94653496e-20],\n",
       "       [1.55160278e-01, 3.87292802e-01, 4.57546949e-01, 1.45196161e-18],\n",
       "       [3.48140448e-02, 9.45998728e-01, 1.91872548e-02, 2.95871235e-19],\n",
       "       [9.79459845e-03, 9.87996161e-01, 2.20929482e-03, 2.52888039e-16],\n",
       "       [4.95618820e-01, 1.98266715e-01, 3.06114554e-01, 1.51087103e-17],\n",
       "       [7.00257346e-03, 5.98267373e-03, 9.87014651e-01, 2.94491249e-18],\n",
       "       [9.99017715e-01, 3.98492382e-04, 5.83746063e-04, 7.97543989e-17],\n",
       "       [2.44852472e-02, 7.20003009e-01, 2.55511761e-01, 9.20889423e-19],\n",
       "       [7.81272113e-01, 1.99306577e-01, 1.94212776e-02, 2.75326343e-19],\n",
       "       [7.62522042e-01, 7.54889622e-02, 1.61989033e-01, 6.51040411e-19],\n",
       "       [9.39615726e-01, 5.77290207e-02, 2.65534222e-03, 3.50130664e-18],\n",
       "       [2.74589837e-01, 6.88552082e-01, 3.68581191e-02, 1.43692468e-20],\n",
       "       [4.22382474e-01, 3.81495446e-01, 1.96122110e-01, 3.17893318e-17],\n",
       "       [1.23221226e-01, 8.76712859e-01, 6.59432626e-05, 7.41117846e-19],\n",
       "       [6.82993889e-01, 3.15306246e-01, 1.69984670e-03, 1.52326633e-18],\n",
       "       [4.57248211e-01, 2.15791717e-01, 3.26960117e-01, 5.46633648e-20],\n",
       "       [7.99747184e-02, 9.13931608e-01, 6.09372836e-03, 3.53297239e-14],\n",
       "       [3.36033046e-01, 4.01356280e-01, 2.62610614e-01, 1.44490100e-19],\n",
       "       [3.36520016e-01, 3.59538645e-01, 3.03941369e-01, 1.20097965e-20],\n",
       "       [5.28982818e-01, 3.81751835e-01, 8.92654285e-02, 1.46490171e-18],\n",
       "       [9.66881096e-01, 1.79880578e-02, 1.51309334e-02, 2.14231717e-20],\n",
       "       [9.33648571e-02, 1.97292466e-04, 9.06437814e-01, 7.91316517e-20],\n",
       "       [4.00223941e-01, 3.36211771e-01, 2.62887686e-01, 6.76595024e-04],\n",
       "       [3.26280668e-02, 9.67036903e-01, 3.35066550e-04, 3.34439689e-18],\n",
       "       [8.67589861e-02, 7.99150765e-01, 1.14090234e-01, 9.75906893e-16],\n",
       "       [6.56702161e-01, 1.36011586e-01, 2.07286328e-01, 1.97244505e-18],\n",
       "       [2.27939114e-02, 8.41045558e-01, 1.36160523e-01, 1.18961780e-21],\n",
       "       [9.69633102e-01, 2.93533839e-02, 1.01351435e-03, 1.49232559e-19],\n",
       "       [6.51717424e-01, 2.34302104e-01, 1.13980502e-01, 7.02041752e-18],\n",
       "       [8.35039690e-02, 2.29841977e-01, 6.86654031e-01, 2.50257575e-19],\n",
       "       [1.51876464e-01, 3.39486450e-02, 8.14174831e-01, 1.03170009e-18],\n",
       "       [8.63181353e-02, 1.90692887e-01, 7.22989023e-01, 5.91970223e-12],\n",
       "       [3.74625951e-01, 3.35160166e-01, 2.90213823e-01, 1.26204956e-17],\n",
       "       [9.68075752e-01, 6.05854811e-03, 2.58656982e-02, 2.83309254e-16],\n",
       "       [5.10806561e-01, 1.14931859e-01, 3.74261528e-01, 8.16596274e-17],\n",
       "       [1.68742687e-01, 8.23718607e-01, 7.53866555e-03, 4.75794024e-17],\n",
       "       [8.99933457e-01, 7.09675476e-02, 2.90990621e-02, 5.65239019e-15],\n",
       "       [9.61204842e-02, 9.02980864e-01, 8.98726867e-04, 8.28168680e-19],\n",
       "       [8.38423073e-01, 1.48402914e-01, 1.31737897e-02, 1.70634621e-07],\n",
       "       [2.55540460e-01, 4.02591705e-01, 3.41867775e-01, 6.80744868e-16],\n",
       "       [6.96968913e-01, 1.75783083e-01, 1.27247974e-01, 5.08644714e-16],\n",
       "       [2.32244805e-02, 1.03778429e-01, 8.72996986e-01, 3.79314920e-17]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cnn = model_cnn.predict(X_test_cnn)\n",
    "pred_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:  [1 2 2 1 1 0 2 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 2 0 1 1 0 1 0 0 2 2 2 0 0 0 1\n",
      " 0 1 0 1 0 2]\n",
      "True labels:       [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "y_pred_cnn = np.argmax(pred_cnn, axis=1)\n",
    "print(\"Predicted labels: \", y_pred_cnn)\n",
    "print(\"True labels:      \", y_test_cnn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy: $20/43$ ($46.51 \\%$)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
